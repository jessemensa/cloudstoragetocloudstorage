PIPELINE JOB: 
FROM LOCAL STORAGE TO CLOUD STORAGE BUCKET TO CLOUD DATAFLOW TO CLOUD STORAGE BUCKET 

CREATE FOLDERS IN CLOUD STORAGE BUCKET 
INPUT FOLDER => UPLOAD INPUT SOURCE FILE HERE & COPY THE PATH 
OUTPUT FOLDER 
TEMP FOLDER 
TEMPLATE FOLDER 


TO EXECUTE A BATCH JOB IN DATAFLOW 
=> SEARCH FOR DATAFLOW 
=> NAVIGATE TO DATAFLOW 
=> CREATE JOB FROM TEMPLATE 
=> JOB NAME  & DATAFLOW TEMPLATE (CUSTOM TEMPLATE) 
=> TEMPLATE PATH (IN THE DATAFLOW BUCKET)
=> TEMPORARY LOCATION (GET IT FROM THE PIPELINE OPTIONS SECTION IN THE CODE) 
=> RUN (STARTS THE JOB) (now job is starting) 
=> CLICK ON THE JOB AND SEE THE DIAG 
=> THIS TAKES A WHILE TO EXECUTE 



